{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: Used LoRA as a PEFT method\n",
    "* Model: Using DistilBERT as transformer model with Sequence Classification learning approach.\n",
    "* Evaluation approach: Evaluated using Trainer class\n",
    "* Fine-tuning dataset: MASSIVE 1.1: A 1M-Example Multilingual Natural Language Understanding Dataset with 52 Typologically-Diverse Languages (https://huggingface.co/datasets/AmazonScience/massive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 676k/676k [00:00<00:00, 8.91MB/s]\n",
      "Downloading data: 100%|██████████| 140k/140k [00:00<00:00, 2.10MB/s]\n",
      "Downloading data: 100%|██████████| 191k/191k [00:00<00:00, 2.90MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f71c14788749009a49b01f9a76e43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81881d8411c04b3e83716546149d5ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a00def084b44dc88fcf2aa8345c259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 11514\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 2033\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 2974\n",
       " })}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "# Load the train, validation and test splits of the AmazonScience/massive dataset\n",
    "dataset = {split: ds for split, ds in zip(splits, load_dataset(\"AmazonScience/massive\", \"en-US\", split=splits))}\n",
    "#print(dataset[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 5757\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 1016\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "     num_rows: 1487\n",
       " })}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = {}\n",
    "for split in splits:\n",
    "  portion = int(dataset[split].shape[0]*0.5) # select 50% from dataset data to speed up training\n",
    "  ds[split] = dataset[split].shuffle(seed=42).select(range(portion))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28c4a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336a9aec0c8348efa707724d16f14c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5757 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0843931805bc41609bf91dfd13221ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92a04c9fbac421c964887c52a50a317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")  #\"gpt2\"\n",
    "tokenized_dataset = {}\n",
    "\n",
    "#tokenizer.pad_token = 'NULL'\n",
    "#tokenizer.add_special_tokens({'pad_token': '!'})\n",
    "for split in splits:\n",
    "  tokenized_dataset[split] = ds[split].map(\n",
    "      lambda x: tokenizer(x[\"utt\"], padding=True, truncation=True, return_tensors=\"pt\"), batched=True\n",
    "  )\n",
    "  tokenized_dataset[split] = tokenized_dataset[split].rename_column(\"scenario\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a7d306dc54456185f00a33fdaec767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "\n",
    "id2label={i: label for i, label in enumerate(tokenized_dataset[\"train\"].features[\"label\"].names)}\n",
    "label2id={label: i for i, label in enumerate(tokenized_dataset[\"train\"].features[\"label\"].names)}\n",
    "\n",
    "        #AutoModelForSequenceClassification\n",
    "        #RobertaForCausalLM\n",
    "        #AutoModelForCausalLM\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    #\"gpt2\",\n",
    "    num_labels=18,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32886e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False # Unfreeze -> True\n",
    "    #print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5176b07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.902759075164795,\n",
       " 'eval_accuracy': 0.09448818897637795,\n",
       " 'eval_runtime': 1.664,\n",
       " 'eval_samples_per_second': 610.592,\n",
       " 'eval_steps_per_second': 38.462}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    #print(list(eval_pred))\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/voice_assistant_interactions\",\n",
    "        # Set the learning rate\n",
    "        learning_rate= 2e-05,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad850fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.01,\n",
    "    bias=\"none\",\n",
    "    task_type='SEQ_CLS',\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DistilBertForMaskedLM']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.config.architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020084b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,503,780 || all params: 67,866,660 || trainable%: 2.21578607227761\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3600/3600 03:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.972813</td>\n",
       "      <td>0.493110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.319200</td>\n",
       "      <td>1.063983</td>\n",
       "      <td>0.730315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.760502</td>\n",
       "      <td>0.808071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.638603</td>\n",
       "      <td>0.830709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.573173</td>\n",
       "      <td>0.848425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.535031</td>\n",
       "      <td>0.853346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>0.510437</td>\n",
       "      <td>0.857283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>0.498108</td>\n",
       "      <td>0.859252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>0.490194</td>\n",
       "      <td>0.855315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>0.857283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-360 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-720 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-1080 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-1440 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-1800 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-2160 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-2520 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-2880 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-3240 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/voice_assistant_interactions_lora/checkpoint-3600 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3600, training_loss=0.916069999270969, metrics={'train_runtime': 194.5722, 'train_samples_per_second': 295.88, 'train_steps_per_second': 18.502, 'total_flos': 592220421776088.0, 'train_loss': 0.916069999270969, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/voice_assistant_interactions_lora\",\n",
    "        # Set the learning rate\n",
    "        learning_rate= 2e-05,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        #label_names = [\"start_positions\", \"end_positions\"],\n",
    "        #label_names=[\"label\"],\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "lora_trainer.train()\n",
    "#lora_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"distilbert-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification, PeftModel\n",
    "\n",
    "peft_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-lora\",\n",
    "    num_labels=18,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    #is_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7d74a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DistilBertForMaskedLM']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.config.architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.48792585730552673,\n",
       " 'eval_accuracy': 0.8572834645669292,\n",
       " 'eval_runtime': 1.2575,\n",
       " 'eval_samples_per_second': 807.927,\n",
       " 'eval_steps_per_second': 50.893}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/voice_assistant_interactions_peft\",\n",
    "        # Set the learning rate\n",
    "        learning_rate= 2e-05,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        #label_names = [\"start_positions\", \"end_positions\"],\n",
    "        #label_names=[\"label\"],\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#peft_trainer.train()\n",
    "peft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need you to mark next monday</td>\n",
       "      <td>calendar</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>let's play my most played song list</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disable alarm for three p. m.</td>\n",
       "      <td>alarm</td>\n",
       "      <td>alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancel alarm</td>\n",
       "      <td>alarm</td>\n",
       "      <td>alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remind me about my schedule for the afternoon</td>\n",
       "      <td>calendar</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pause the book</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hi can you please turn lower the lights</td>\n",
       "      <td>iot</td>\n",
       "      <td>iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>when is easter in the year two thousand and eighteen</td>\n",
       "      <td>datetime</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>speak loudly</td>\n",
       "      <td>audio</td>\n",
       "      <td>audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how do i make a turkey</td>\n",
       "      <td>cooking</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>please compose a new email to coworker</td>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>when does the super bowl officially start</td>\n",
       "      <td>calendar</td>\n",
       "      <td>qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i need to get a ticket via train to orlando from hwood</td>\n",
       "      <td>transport</td>\n",
       "      <td>transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>please add oranges to my grocery list</td>\n",
       "      <td>lists</td>\n",
       "      <td>lists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>add a wrist watch to the shopping list</td>\n",
       "      <td>lists</td>\n",
       "      <td>lists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>please play the latest bill simmons podcast</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>how long should i cook a steak to achieve medium rare</td>\n",
       "      <td>cooking</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hey what will the weather be like to today in los angeles california</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i can barely hear you</td>\n",
       "      <td>audio</td>\n",
       "      <td>audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>where is the nearest walmart</td>\n",
       "      <td>transport</td>\n",
       "      <td>recommendation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               utterance  \\\n",
       "0                                         i need you to mark next monday   \n",
       "1                                    let's play my most played song list   \n",
       "2                                          disable alarm for three p. m.   \n",
       "3                                                           cancel alarm   \n",
       "4                          remind me about my schedule for the afternoon   \n",
       "5                                                         pause the book   \n",
       "6                                hi can you please turn lower the lights   \n",
       "7                   when is easter in the year two thousand and eighteen   \n",
       "8                                                           speak loudly   \n",
       "9                                                 how do i make a turkey   \n",
       "10                                please compose a new email to coworker   \n",
       "11                             when does the super bowl officially start   \n",
       "12                i need to get a ticket via train to orlando from hwood   \n",
       "13                                 please add oranges to my grocery list   \n",
       "14                                add a wrist watch to the shopping list   \n",
       "15                           please play the latest bill simmons podcast   \n",
       "16                 how long should i cook a steak to achieve medium rare   \n",
       "17  hey what will the weather be like to today in los angeles california   \n",
       "18                                                 i can barely hear you   \n",
       "19                                          where is the nearest walmart   \n",
       "\n",
       "   predicted_label           label  \n",
       "0         calendar        calendar  \n",
       "1             play            play  \n",
       "2            alarm           alarm  \n",
       "3            alarm           alarm  \n",
       "4         calendar        calendar  \n",
       "5             play            play  \n",
       "6              iot             iot  \n",
       "7         datetime        datetime  \n",
       "8            audio           audio  \n",
       "9          cooking         cooking  \n",
       "10           email           email  \n",
       "11        calendar              qa  \n",
       "12       transport       transport  \n",
       "13           lists           lists  \n",
       "14           lists           lists  \n",
       "15            play            play  \n",
       "16         cooking         cooking  \n",
       "17         weather         weather  \n",
       "18           audio           audio  \n",
       "19       transport  recommendation  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "import pandas as pd\n",
    "\n",
    "review_items = tokenized_dataset[\"test\"].select(range(20)) #Using test data set for the 1st time\n",
    "\n",
    "results = peft_trainer.predict(review_items)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"utterance\": [item[\"utt\"] for item in review_items],\n",
    "        \"predicted_label\": [id2label[id] for id in results.predictions.argmax(axis=1)],\n",
    "        \"label\": [id2label[id] for id in results.label_ids]\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99229e0f",
   "metadata": {},
   "source": [
    "Accuracy comparison:\n",
    "\n",
    "Pre-trained model:'eval_accuracy': 0.09448818897637795,\n",
    "\n",
    "PEFT model after training: 'eval_accuracy': 0.8572834645669292,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
